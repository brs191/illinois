{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Project #5: Video Stitching and Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS445: Computational Photography - Fall 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Stitch two key frames <img src=\"images/project_5/image005.jpg\" alt=\"Drawing\" style=\"float: right; width: 450px\"/>\n",
    "\n",
    "#### This involves:\n",
    "1. compute homography H between two frames; \n",
    "2. project each frame onto the same surface;\n",
    "3. blend the surfaces.\n",
    "\n",
    "\n",
    "\n",
    "Check that your homography is correct by plotting four points that form a square in frame 270 and their projections in each image, like this:\n",
    "<p>\n",
    "    <img src=\"images/project_5/image002.jpg\" alt=\"Drawing\"/>\n",
    "    <img src=\"images/project_5/image004.jpg\" alt=\"Drawing\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python==3.4.2.17\n",
    "# !pip install opencv-contrib-python==3.4.2.17\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy.linalg import svd, inv\n",
    "import utils\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images location\n",
    "# im1 = './images/input/frames/f0001.jpg'\n",
    "im1 = './images/input/frames/f0450.jpg'\n",
    "im2 = './images/input/frames/f0270.jpg'\n",
    "\n",
    "# Load an color image in grayscale\n",
    "im1 = cv2.imread(im1)\n",
    "im2 = cv2.imread(im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_homography(Ia,Ib, homography_func=None,normalization_func=None):\n",
    "    '''\n",
    "    Computes a homography that maps points from Ia to Ib\n",
    "\n",
    "    Input: Ia and Ib are images\n",
    "    Output: H is the homography\n",
    "\n",
    "    '''\n",
    "    if Ia.dtype == 'float32' and Ib.dtype == 'float32':\n",
    "        Ia = (Ia*255).astype(np.uint8)\n",
    "        Ib = (Ib*255).astype(np.uint8)\n",
    "    \n",
    "    Ia_gray = cv2.cvtColor(Ia,cv2.COLOR_BGR2GRAY)\n",
    "    Ib_gray = cv2.cvtColor(Ib,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initiate SIFT detector\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp_a, des_a = sift.detectAndCompute(Ia_gray,None)\n",
    "    kp_b, des_b = sift.detectAndCompute(Ib_gray,None)    \n",
    "    \n",
    "    # BFMatcher with default params\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des_a,des_b, k=2)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good.append(m)\n",
    "   \n",
    "    numMatches = int(len(good))\n",
    "\n",
    "    matches = good\n",
    "\n",
    "    # Xa and Xb are 3xN matrices that contain homogeneous coordinates for the N\n",
    "    # matching points for each image\n",
    "    Xa = np.ones((3,numMatches))\n",
    "    Xb = np.ones((3,numMatches))\n",
    "    \n",
    "    for idx, match_i in enumerate(matches):\n",
    "        Xa[:,idx][0:2] = kp_a[match_i.queryIdx].pt\n",
    "        Xb[:,idx][0:2] = kp_b[match_i.trainIdx].pt\n",
    "\n",
    "    ## RANSAC\n",
    "    niter = 1000\n",
    "    best_score = 0\n",
    "\n",
    "    for t in range(niter):\n",
    "        # estimate homography\n",
    "        subset = np.random.choice(numMatches, 4, replace=False)\n",
    "        pts1 = Xa[:,subset]\n",
    "        pts2 = Xb[:,subset]\n",
    "        \n",
    "        H_t = homography_func(pts1, pts2, normalization_func) # edit helper code below (computeHomography)\n",
    "\n",
    "        # score homography\n",
    "        Xb_ = np.dot(H_t, Xa) # project points from first image to second using H\n",
    "        du = Xb_[0,:]/Xb_[2,:] - Xb[0,:]/Xb[2,:]\n",
    "        dv = Xb_[1,:]/Xb_[2,:] - Xb[1,:]/Xb[2,:]\n",
    "\n",
    "        ok_t = np.sqrt(du**2 + dv**2) < 1  # you may need to play with this threshold\n",
    "        score_t = sum(ok_t)\n",
    "\n",
    "        if score_t > best_score:\n",
    "            best_score = score_t\n",
    "            H = H_t\n",
    "            in_idx = ok_t\n",
    "            pt1 = pts1\n",
    "            pt2 = pts2\n",
    "    \n",
    "    print('best score: {:02f}'.format(best_score))\n",
    "\n",
    "    # Optionally, you may want to re-estimate H based on inliers\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeHomography(pts1, pts2,normalization_func=None):\n",
    "    '''\n",
    "    Compute homography that maps from pts1 to pts2 using SVD\n",
    "     \n",
    "    Input: pts1 and pts2 are 3xN matrices for N points in homogeneous\n",
    "    coordinates. \n",
    "    \n",
    "    Output: H is a 3x3 matrix, such that pts2~=H*pts1\n",
    "    '''\n",
    "#     print(\"pts1.shape is \", pts1.shape)\n",
    "#     print(\"pts1 is \", pts1)\n",
    "    N = pts1.shape[1]\n",
    "    A = np.zeros((2*N, 9))\n",
    "\n",
    "    for i in range(N):\n",
    "        x = pts1[:, i]\n",
    "        xi = pts2[:, i]\n",
    "        u, v = x[0], x[1]\n",
    "        ui, vi = xi[0], xi[1]\n",
    "        A[2*i, :] = np.array([-u, -v, -1, 0, 0, 0, u*ui, v*ui, ui])\n",
    "        A[2*i+1, :] = np.array([0, 0, 0, -u, -v, -1, u*vi, v*vi, vi])\n",
    "        \n",
    "    u, s, vt = np.linalg.svd(A)\n",
    "    h = vt[vt.shape[0]-1, :]\n",
    "#     h = vt[:, -1]\n",
    "    return np.reshape(h, (3,3))\n",
    "#     raise Exception(\"TODO in computeHomography() not implemented\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt1, pt2, H = auto_homography(im1, im2, computeHomography)\n",
    "# Computes a homography that maps points from Ia to Ib \n",
    "H = auto_homography(im1, im2, computeHomography) #h (450, 270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the interest points on im1 and im2 (450)\n",
    "plotx_im1 = np.array([100, 240, 240, 100, 100])\n",
    "ploty_im1 = np.array([50, 50, 200, 200, 50])\n",
    "plotz_im1 = np.ones(5)\n",
    "plot_im1 = np.array([plotx_im1, ploty_im1, plotz_im1])\n",
    "\n",
    "plot_im2 = np.dot(H, plot_im1)\n",
    "plot_im2 = plot_im2 / plot_im2[-1]\n",
    "\n",
    "print(\"plot_im2 \", plot_im2)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(221)\n",
    "plt.imshow(cv2.cvtColor(im1, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "plt.imshow(cv2.cvtColor(im2, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "plt.imshow(cv2.cvtColor(im1, cv2.COLOR_BGR2RGB))\n",
    "ax3.plot(plot_im1[0], plot_im1[1], 'b')\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "plt.imshow(cv2.cvtColor(im2, cv2.COLOR_BGR2RGB))\n",
    "ax4.plot(plot_im2[0], plot_im2[1], 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example usage of cv2.warpPerspective\n",
    "## Tips: \n",
    "##      1.For reference frame, you may just use identity matrix for the transformation.\n",
    "##      2.To avoid some pixels being mapped to negative locations, you may want to apply translations first.\n",
    "# projectedWidth = 1600\n",
    "# projectedHeight = 500\n",
    "# projectedSource = cv2.warpPerspective(im1, sourceHomography, (projectedWidth, projectedHeight))\n",
    "# projectedReference = cv2.warpPerspective(im2, refHomography, (projectedWidth, projectedHeight))\n",
    "\n",
    "# ## Example usage of utils.blendImages\n",
    "# blendedOutput = utils.blendImages(projectedSource, projectedReference)\n",
    "# plt.figure()\n",
    "# blendedOutput= cv2.cvtColor(blendedOutput, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(blendedOutput)\n",
    "\n",
    "projectedWidth = 1600\n",
    "projectedHeight = 500\n",
    "\n",
    "sourceHomography = H\n",
    "refHomography = np.identity(3)\n",
    "\n",
    "projectedSource = cv2.warpPerspective(im1, sourceHomography, (projectedWidth, projectedHeight))\n",
    "projectedReference = cv2.warpPerspective(im2, refHomography, (projectedWidth, projectedHeight))\n",
    "\n",
    "# Example usage of utils.blendImages\n",
    "blendedOutput = utils.blendImages(projectedSource, projectedReference)\n",
    "plt.figure()\n",
    "blendedOutput= cv2.cvtColor(blendedOutput, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(blendedOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Panorama using five key frames\n",
    "\n",
    "In this part you will produce a panorama using five key frames. Let's determine frames [90, 270, 450, 630, 810] as key frames. The goal is to map all the five frames onto the plane corresponding to frame 450 (that we also call the _reference frame_). For the frames 270 and 630 you can follow the instructions in part 1.\n",
    "\n",
    "<img src=\"images/project_5/header.jpg\" alt=\"Drawing\" style=\"float: center; width: 500px\"/>\n",
    "\n",
    "Mapping frame 90 to frame 450 is difficult because they share very little area. Therefore you need to perform a two stage mapping by using frame 270 as a guide. Compute one projection from 90 to 270 and one from 270 to 450 and multiply the two matrices. This produces a projection from 90 to 450 even though these frames have very little area in common\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = cv2.cvtColor(cv2.imread('./images/input/frames/f0450.jpg'), cv2.COLOR_BGR2RGB)\n",
    "canvas = np.zeros((500, 1600, 3), 'uint8')\n",
    "x_offset = 10\n",
    "y_offset = 50\n",
    "canvas[x_offset:x_offset+img.shape[0], y_offset:y_offset+img.shape[1]] = img\n",
    "    \n",
    "plt.figure()\n",
    "plt.imshow(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_frames =[90, 270, 450, 630, 810]\n",
    "reference_frame = 450\n",
    "reference_idx = master_frames.index(reference_frame)\n",
    "\n",
    "im1 = cv2.imread('./images/input/frames/f0090.jpg')\n",
    "im2 = cv2.imread('./images/input/frames/f0270.jpg')\n",
    "im3 = cv2.imread('./images/input/frames/f0450.jpg')\n",
    "im4 = cv2.imread('./images/input/frames/f0630.jpg')\n",
    "im5 = cv2.imread('./images/input/frames/f0810.jpg')\n",
    "\n",
    "H_90 = auto_homography(im1, im2, computeHomography)\n",
    "H_270 = auto_homography(im2, im3, computeHomography)\n",
    "H_640 = auto_homography(im4, im3, computeHomography)\n",
    "H_810 = auto_homography(im5, im4, computeHomography)\n",
    "\n",
    "leftOfRef = np.matmul(H_90, H_270)\n",
    "rightOfRef = np.matmul(H_810, H_640)\n",
    "\n",
    "I = np.identity(3)\n",
    "img_warped_450 = cv2.warpPerspective(im3, I, (projectedWidth, projectedHeight))\n",
    "\n",
    "img_warped_90 = cv2.warpPerspective(im3, H_90, (projectedWidth, projectedHeight))\n",
    "img_warped_270 = cv2.warpPerspective(im3, H_270, (projectedWidth, projectedHeight))\n",
    "img_warped_640 = cv2.warpPerspective(im3, H_640, (projectedWidth, projectedHeight))\n",
    "img_warped_810 = cv2.warpPerspective(im3, H_810, (projectedWidth, projectedHeight))\n",
    "\n",
    "print(\"h, w \", img_warped_450.shape)\n",
    "out = np.zeros((600, 1600, 3), 'uint8')\n",
    "h,w,_ = img_warped_450.shape\n",
    "\n",
    "for r in range(h):\n",
    "    for c in range(w):\n",
    "        out[r,c] = img_warped_90[r,c]\n",
    "        \n",
    "for r in range(h):\n",
    "    for c in range(w):\n",
    "        if out[r,c,0] == 0 and out[r,c,1] == 0 and out[r,c,2] == 0:\n",
    "            out[r,c] = img_warped_270[r,c]\n",
    "    \n",
    "for r in range(h):\n",
    "    for c in range(w):\n",
    "        if out[r,c,0] == 0 and out[r,c,1] == 0 and out[r,c,2] == 0:\n",
    "            out[r,c] = img_warped_450[r,c]\n",
    "            \n",
    "for r in range(h):\n",
    "    for c in range(w):\n",
    "        if out[r,c,0] == 0 and out[r,c,1] == 0 and out[r,c,2] == 0:\n",
    "            out[r,c] = img_warped_640[r,c]\n",
    "            \n",
    "for r in range(h):\n",
    "    for c in range(w):\n",
    "        if out[r,c,0] == 0 and out[r,c,1] == 0 and out[r,c,2] == 0:\n",
    "            out[r,c] = img_warped_810[r,c]\n",
    "    \n",
    "plt.figure()\n",
    "plt.imshow(out)\n",
    "# plt.imshow(cv2.cvtColor(img_warped_450, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Map the video to the reference plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_frames = 'images/input/frames'\n",
    "filenames = []\n",
    "filesinfo = os.scandir(dir_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [f.path for f in filesinfo if f.name.endswith(\".jpg\")]\n",
    "filenames.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameCount = len(filenames)\n",
    "frameHeight, frameWidth, frameChannels = cv2.imread(filenames[0]).shape\n",
    "frames = np.zeros((frameCount, frameHeight, frameWidth, frameChannels),dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, file_i in enumerate(filenames):\n",
    "    frames[idx] = cv2.cvtColor(cv2.imread(file_i), cv2.COLOR_BGR2RGB) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Create background panorama\n",
    "\n",
    "In this part you will remove moving objects from the video and create a background panorama that should incorporate pixels from all the frames.\n",
    "\n",
    "In the video you produced in __part 3__ each pixel appears in several frames. You need to estimate which of the many colors correspond to the background. We take advantage of the fact that the background color is fixed while the foreground color changes frequently (because foreground moves).\n",
    "\n",
    "<img src=\"images/project_5/background.jpg\" alt=\"Drawing\" style=\"float: center; width: 500px\"/>\n",
    "\n",
    "\n",
    "For each pixel in the sequence of __part 3__, determine all valid colors (colors that come from all frames that overlap that pixel). You can experiment with different methods for determining the background color of each pixel, as discussed in class. Perform the same procedure for all pixels and generate output. The output should be a completed panorama showing only pixels of background or non-moving objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Create background movie\n",
    "\n",
    "Map the background panorama to the movie coordinates. For each frame of the movie, say frame 1, you need to estimate a projection from the panorama to frame 1. Note, you should be able to re-use the homographies that you estimated in __Part 3__. Perform this for all frames and generate a movie that looks like the input movie but shows only background pixels. All moving objects that belong to the foreground must be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: Create foreground movie\n",
    "\n",
    "In the background video, moving objects are removed. In each frame, those pixels that are different enough than the background color are considered foreground. For each frame determine foreground pixels and generate a movie that only includes foreground pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bells and whistles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
